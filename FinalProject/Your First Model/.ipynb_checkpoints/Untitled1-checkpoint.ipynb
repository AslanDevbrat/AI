{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Dict, List\n",
    "import logging\n",
    "\n",
    "from overrides import overrides\n",
    "\n",
    "from allennlp.common.file_utils import cached_path\n",
    "from allennlp.data.dataset_readers.dataset_reader import DatasetReader\n",
    "from allennlp.data.fields import LabelField, TextField, Field, ListField, ArrayField\n",
    "from allennlp.data.instance import Instance\n",
    "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n",
    "from allennlp.data.tokenizers import Tokenizer, SpacyTokenizer, WhitespaceTokenizer, PretrainedTransformerTokenizer\n",
    "from allennlp.common.checks import ConfigurationError\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "@DatasetReader.register(\"mimics\")\n",
    "class MIMICSDatasetReader(DatasetReader):\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer: Tokenizer = None,\n",
    "        token_indexers: Dict[str, TokenIndexer] = None,\n",
    "        max_tokens: int = None,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.tokenizer = tokenizer or PretrainedTransformerTokenizer('bert-base-uncased')\n",
    "        self.token_indexers = token_indexers or {'tokens': SingleIdTokenIndexer()}\n",
    "        self.max_tokens = max_tokens\n",
    "        \n",
    "\n",
    "    @overrides\n",
    "    def _read(self, file_path: str):\n",
    "        logger.info(\"Reading instances from lines in file at: %s\", file_path)\n",
    "\n",
    "        df = pd.read_csv(cached_path(file_path), sep='\\t')\n",
    "        \n",
    "        _options_columns = [f'option_{i}' for i in range(1, 6)] # option_1, ..., option_5\n",
    "        _label_columns = df.filter(regex=r\"option\\_.*\\_\\d\", axis=1).columns.tolist() # option_label_1, ..., option_label_5\n",
    "        \n",
    "        columns = ['query','question', *_options_columns, *_label_columns]\n",
    "        df = df[columns]\n",
    "\n",
    "        df['options'] = df[_options_columns].fillna('').values.tolist()\n",
    "        df['labels'] = df[_label_columns].values.tolist()\n",
    "\n",
    "        df = df.drop(columns=[*_options_columns, *_label_columns])\n",
    "\n",
    "        for row in df.to_dict(orient='records'):\n",
    "            yield self.text_to_instance(**row)\n",
    "\n",
    "    def _make_textfield(self, text: str):\n",
    "        tokens = self.tokenizer.tokenize(text)\n",
    "        if self.max_tokens:\n",
    "            tokens = tokens[:self.max_tokens]\n",
    "        return TextField(tokens, token_indexers=self.token_indexers)\n",
    "\n",
    "    @overrides\n",
    "    def text_to_instance(\n",
    "        self,\n",
    "        query: str, \n",
    "        question: str,\n",
    "        options: List[str],\n",
    "        labels: List[str] = None\n",
    "    ) -> Instance:  # type: ignore\n",
    "        options = list(filter(None, options))\n",
    "        \n",
    "        if labels:\n",
    "            assert all(l >= 0 for l in labels)\n",
    "            assert all((l == 0) for l in labels[len(options):])\n",
    "            labels = labels[:len(options)]\n",
    "            \n",
    "        # query_field = self._make_textfield(query)\n",
    "        token_field = self._make_textfield((query, question))\n",
    "\n",
    "        options_field = ListField([self._make_textfield(o) for o in options])\n",
    "        # fields = { 'query': query_field, 'question': question_field, 'options': options_field }\n",
    "        fields = { 'tokens': token_field, 'options': options_field }\n",
    "\n",
    "        if labels:\n",
    "            labels = list(map(float, filter(lambda x: not pd.isnull(x), labels)))            \n",
    "            fields['labels'] = ArrayField(np.array(labels), padding_value=-1)\n",
    "        \n",
    "        return Instance(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from allennlp.common.registrable import Registrable\n",
    "from allennlp.data import TextFieldTensors\n",
    "\n",
    "class RelevanceMatcher(Registrable, nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(input_dim, 1, bias=False)\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        query_embeddings: TextFieldTensors, \n",
    "        candidates_embeddings: TextFieldTensors,\n",
    "        query_mask: torch.Tensor = None,\n",
    "        candidates_mask: torch.Tensor = None\n",
    "    ):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://github.com/joelgrus/kaggle-toxic-allennlp/blob/master/toxic/training/metrics/multilabel_f1.py\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "\n",
    "from allennlp.training.metrics.metric import Metric\n",
    "\n",
    "\n",
    "@Metric.register(\"multilabel-f1\")\n",
    "class MultiLabelF1Measure(Metric):\n",
    "    \"\"\"\n",
    "    Computes multilabel F1. Assumes that predictions are 0 or 1.\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        self._true_positives = 0.0\n",
    "        self._true_negatives = 0.0\n",
    "        self._false_positives = 0.0\n",
    "        self._false_negatives = 0.0\n",
    "\n",
    "    def __call__(self,\n",
    "                 predictions: torch.LongTensor,\n",
    "                 gold_labels: torch.LongTensor):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        predictions : ``torch.Tensor``, required.\n",
    "            A tensor of 0 and 1 predictions of shape (batch_size, ..., num_labels).\n",
    "        gold_labels : ``torch.Tensor``, required.\n",
    "            A tensor of 0 and 1 predictions of shape (batch_size, ..., num_labels).\n",
    "        \"\"\"\n",
    "        self._true_positives += (predictions * gold_labels).sum().item()\n",
    "        self._false_positives += (predictions * (1 - gold_labels)).sum().item()\n",
    "        self._true_negatives += ((1 - predictions) * (1 - gold_labels)).sum().item()\n",
    "        self._false_negatives += ((1 - predictions) * gold_labels).sum().item()\n",
    "\n",
    "    def get_metric(self, reset: bool = False):\n",
    "        \"\"\"\n",
    "        Returns\n",
    "        -------\n",
    "        A tuple of the following metrics based on the accumulated count statistics:\n",
    "        precision : float\n",
    "        recall : float\n",
    "        f1-measure : float\n",
    "        \"\"\"\n",
    "        predicted_positives = self._true_positives + self._false_positives\n",
    "        actual_positives = self._true_positives + self._false_negatives\n",
    "\n",
    "        precision = self._true_positives / predicted_positives if predicted_positives > 0 else 0\n",
    "        recall = self._true_positives / actual_positives if actual_positives > 0 else 0\n",
    "\n",
    "        if precision + recall > 0:\n",
    "            f1_measure = 2 * precision * recall / (precision + recall)\n",
    "        else:\n",
    "            f1_measure = 0\n",
    "\n",
    "        if reset:\n",
    "            self.reset()\n",
    "        return precision, recall, f1_measure\n",
    "\n",
    "    def reset(self):\n",
    "        self._true_positives = 0.0\n",
    "        self._true_negatives = 0.0\n",
    "        self._false_positives = 0.0\n",
    "        self._false_negatives = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import torch\n",
    "\n",
    "from typing import Optional, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from allennlp.training.metrics.metric import Metric\n",
    "\n",
    "class RankingMetric(Metric):\n",
    "    def __init__(\n",
    "        self,\n",
    "        padding_value: int = -1\n",
    "    ) -> None:\n",
    "        self._padding_value = padding_value\n",
    "        self.reset()\n",
    "        \n",
    "    def __call__(\n",
    "            self,\n",
    "            predictions: torch.LongTensor,\n",
    "            gold_labels: torch.LongTensor,\n",
    "            mask: torch.LongTensor = None\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        predictions : ``torch.Tensor``, required.\n",
    "            A tensor of real-valued predictions of shape (batch_size, slate_length).\n",
    "        gold_labels : ``torch.Tensor``, required.\n",
    "            A tensor of real-valued labels of shape (batch_size, slate_length).\n",
    "        \"\"\"\n",
    "        \n",
    "        if mask is None:\n",
    "            mask = torch.ones_like(gold_labels).bool()\n",
    "        \n",
    "        self._all_predictions.append(predictions.detach().cpu())\n",
    "        self._all_gold_labels.append(gold_labels.detach().cpu()) \n",
    "        self._all_masks.append(mask.detach().cpu())\n",
    "        \n",
    "    @property\n",
    "    def predictions(self):\n",
    "        return torch.cat(self._all_predictions, dim=0)\n",
    "    \n",
    "    @property\n",
    "    def gold_labels(self):\n",
    "        return torch.cat(self._all_gold_labels, dim=0)\n",
    "    \n",
    "    @property\n",
    "    def masks(self):\n",
    "        return torch.cat(self._all_masks, dim=0)\n",
    "        \n",
    "    def get_metric(self, reset: bool = False):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def reset(self):\n",
    "        self._all_predictions = []\n",
    "        self._all_gold_labels = []\n",
    "        self._all_masks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# source: https://github.com/allegro/allRank/blob/master/allrank/models/metrics.py\n",
    "# reference: https://github.com/allenai/allennlp/blob/master/allennlp/training/metrics/auc.py\n",
    "\n",
    "from typing import Optional, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "#from allennlp.training.metrics.metric import Metric\n",
    "\n",
    "#from allenrank.training.metrics.ranking_metric import RankingMetric\n",
    "\n",
    "import torchsnooper\n",
    "\n",
    "\n",
    "def __apply_mask_and_get_true_sorted_by_preds(y_pred, y_true, padding_indicator=-1):\n",
    "    mask = y_true == padding_indicator\n",
    "\n",
    "    y_pred[mask] = float('-inf')\n",
    "    y_true[mask] = 0.0\n",
    "\n",
    "    _, indices = y_pred.sort(descending=True, dim=-1)\n",
    "    return torch.gather(y_true, dim=1, index=indices)\n",
    "\n",
    "def pad_to_max_length(seq: List[torch.Tensor], padding_value: int = -1):\n",
    "    return torch.nn.utils.rnn.pad_sequence(seq, batch_first=True, padding_value=padding_value)\n",
    "\n",
    "\n",
    "@Metric.register(\"ndcg\")\n",
    "class NDCG(RankingMetric):\n",
    "    \"\"\"\n",
    "    Computes NDCG.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_metric(self, reset: bool = False):        \n",
    "        score = ndcg(self.predictions, self.gold_labels, padding_indicator=self._padding_value).mean().item()\n",
    "\n",
    "        if reset:\n",
    "            self.reset()\n",
    "        return score\n",
    "\n",
    "\n",
    "def ndcg(y_pred, y_true, ats=None, gain_function=lambda x: torch.pow(2, x) - 1, padding_indicator=-1):\n",
    "    \"\"\"\n",
    "    Normalized Discounted Cumulative Gain at k.\n",
    "    Compute NDCG at ranks given by ats or at the maximum rank if ats is None.\n",
    "    :param y_pred: predictions from the model, shape [batch_size, slate_length]\n",
    "    :param y_true: ground truth labels, shape [batch_size, slate_length]\n",
    "    :param ats: optional list of ranks for NDCG evaluation, if None, maximum rank is used\n",
    "    :param gain_function: callable, gain function for the ground truth labels, e.g. torch.pow(2, x) - 1\n",
    "    :param padding_indicator: an indicator of the y_true index containing a padded item, e.g. -1\n",
    "    :return: NDCG values for each slate and rank passed, shape [batch_size, len(ats)]\n",
    "    \"\"\"\n",
    "    idcg = dcg(y_true, y_true, ats, gain_function, padding_indicator)\n",
    "    ndcg_ = dcg(y_pred, y_true, ats, gain_function, padding_indicator) / idcg\n",
    "    idcg_mask = idcg == 0\n",
    "    ndcg_[idcg_mask] = 0.  # if idcg == 0 , set ndcg to 0\n",
    "\n",
    "    assert (ndcg_ < 0.0).sum() >= 0, \"every ndcg should be non-negative\"\n",
    "\n",
    "    return ndcg_\n",
    "\n",
    "\n",
    "def dcg(y_pred, y_true, ats=None, gain_function=lambda x: torch.pow(2, x) - 1, padding_indicator=-1):\n",
    "    \"\"\"\n",
    "    Discounted Cumulative Gain at k.\n",
    "    Compute DCG at ranks given by ats or at the maximum rank if ats is None.\n",
    "    :param y_pred: predictions from the model, shape [batch_size, slate_length]\n",
    "    :param y_true: ground truth labels, shape [batch_size, slate_length]\n",
    "    :param ats: optional list of ranks for DCG evaluation, if None, maximum rank is used\n",
    "    :param gain_function: callable, gain function for the ground truth labels, e.g. torch.pow(2, x) - 1\n",
    "    :param padding_indicator: an indicator of the y_true index containing a padded item, e.g. -1\n",
    "    :return: DCG values for each slate and evaluation position, shape [batch_size, len(ats)]\n",
    "    \"\"\"\n",
    "    y_true = y_true.clone()\n",
    "    y_pred = y_pred.clone()\n",
    "\n",
    "    actual_length = y_true.shape[1]\n",
    "\n",
    "    if ats is None:\n",
    "        ats = [actual_length]\n",
    "    ats = [min(at, actual_length) for at in ats]\n",
    "\n",
    "    true_sorted_by_preds = __apply_mask_and_get_true_sorted_by_preds(y_pred, y_true, padding_indicator)\n",
    "\n",
    "    discounts = (torch.tensor(1) / torch.log2(torch.arange(true_sorted_by_preds.shape[1], dtype=torch.float) + 2.0)).to(\n",
    "        device=true_sorted_by_preds.device)\n",
    "\n",
    "    gains = gain_function(true_sorted_by_preds)\n",
    "\n",
    "    discounted_gains = (gains * discounts)[:, :np.max(ats)]\n",
    "\n",
    "    cum_dcg = torch.cumsum(discounted_gains, dim=1)\n",
    "\n",
    "    ats_tensor = torch.tensor(ats, dtype=torch.long) - torch.tensor(1)\n",
    "\n",
    "    dcg = cum_dcg[:, ats_tensor]\n",
    "\n",
    "    return dcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from allennlp.training.metrics.metric import Metric\n",
    "\n",
    "#from allenrank.training.metrics.ranking_metric import RankingMetric\n",
    "\n",
    "import torchsnooper\n",
    "\n",
    "\n",
    "@Metric.register(\"mrr\")\n",
    "class MRR(RankingMetric):\n",
    "    def get_metric(self, reset: bool = False):\n",
    "        predictions = torch.cat(self._all_predictions, dim=0)\n",
    "        labels = torch.cat(self._all_gold_labels, dim=0)\n",
    "        masks = torch.cat(self._all_masks, dim=0)\n",
    "        \n",
    "        score = mrr(predictions, labels, masks).item()\n",
    "\n",
    "        if reset:\n",
    "            self.reset()\n",
    "        return score\n",
    "    \n",
    "    \n",
    "# https://stackoverflow.com/a/60202801/6766123\n",
    "def first_nonzero(t):\n",
    "    t = t.masked_fill(t != 0, 1)\n",
    "    idx = torch.arange(t.size(-1), 0, -1).type_as(t)\n",
    "    indices = torch.argmax(t * idx, 1, keepdim=True)\n",
    "    return indices\n",
    "\n",
    "\n",
    "def mrr(y_pred, y_true, mask):\n",
    "    y_pred = y_pred.masked_fill(~mask, -1)\n",
    "    y_true = y_true.ge(y_true.max(dim=-1, keepdim=True).values).float()\n",
    "\n",
    "    _, idx = y_pred.sort(descending=True, dim=-1)\n",
    "    ordered_truth = y_true.gather(1, idx)\n",
    "    \n",
    "    gold = torch.arange(y_true.size(-1)).unsqueeze(0).type_as(y_true)\n",
    "    _mrr = (ordered_truth / (gold + 1)) * mask\n",
    "    \n",
    "    return _mrr.gather(1, first_nonzero(ordered_truth)).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Optional\n",
    "\n",
    "from overrides import overrides\n",
    "import torch\n",
    "\n",
    "from allennlp.data import TextFieldTensors, Vocabulary\n",
    "from allennlp.models.model import Model\n",
    "from allennlp.modules import FeedForward, Seq2SeqEncoder, Seq2VecEncoder, TextFieldEmbedder, TimeDistributed\n",
    "from allennlp.nn import InitializerApplicator, util\n",
    "from allennlp.nn.util import get_text_field_mask\n",
    "from allennlp.training.metrics import CategoricalAccuracy, BooleanAccuracy, Auc, F1Measure, FBetaMeasure, PearsonCorrelation\n",
    "\n",
    "#from allenrank.modules.relevance.base import RelevanceMatcher\n",
    "#from allenrank.training.metrics.multilabel_f1 import MultiLabelF1Measure\n",
    "#from allenrank.training.metrics import NDCG, MRR\n",
    "\n",
    "import torchsnooper\n",
    "\n",
    "\n",
    "@Model.register(\"ranker\")\n",
    "class DocumentRanker(Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab: Vocabulary,\n",
    "        text_field_embedder: TextFieldEmbedder,\n",
    "        relevance_matcher: RelevanceMatcher,\n",
    "        dropout: float = None,\n",
    "        num_labels: int = None,\n",
    "        initializer: InitializerApplicator = InitializerApplicator(),\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "\n",
    "        super().__init__(vocab, **kwargs)\n",
    "        self._text_field_embedder = text_field_embedder\n",
    "        self._relevance_matcher = TimeDistributed(relevance_matcher)\n",
    "\n",
    "        self._dropout = dropout and torch.nn.Dropout(dropout)\n",
    "\n",
    "        self._auc = Auc()\n",
    "        self._mrr = MRR(padding_value=-1)\n",
    "        self._ndcg = NDCG(padding_value=-1)\n",
    "        \n",
    "        self._loss = torch.nn.MSELoss(reduction='none')\n",
    "        initializer(self)\n",
    "\n",
    "    # @torchsnooper.snoop()\n",
    "    def forward(  # type: ignore\n",
    "        self, \n",
    "        tokens: TextFieldTensors, # batch * words\n",
    "        options: TextFieldTensors, # batch * num_options * words\n",
    "        labels: torch.IntTensor = None # batch * num_options\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        embedded_text = self._text_field_embedder(tokens)\n",
    "        mask = get_text_field_mask(tokens).long()\n",
    "\n",
    "        embedded_options = self._text_field_embedder(options, num_wrapping_dims=1) # options_mask.dim() - 2\n",
    "        options_mask = get_text_field_mask(options).long()\n",
    "\n",
    "        if self._dropout:\n",
    "            embedded_text = self._dropout(embedded_text)\n",
    "            embedded_options = self._dropout(embedded_options)\n",
    "\n",
    "        \"\"\"\n",
    "        This isn't exactly a 'hack', but it's definitely not the most efficient way to do it.\n",
    "        Our matcher expects a single (query, document) pair, but we have (query, [d_0, ..., d_n]).\n",
    "        To get around this, we expand the query embeddings to create these pairs, and then\n",
    "        flatten both into the 3D tensor [batch*num_options, words, dim] expected by the matcher. \n",
    "        The expansion does this:\n",
    "        [\n",
    "            (q_0, [d_{0,0}, ..., d_{0,n}]), \n",
    "            (q_1, [d_{1,0}, ..., d_{1,n}])\n",
    "        ]\n",
    "        =>\n",
    "        [\n",
    "            [ (q_0, d_{0,0}), ..., (q_0, d_{0,n}) ],\n",
    "            [ (q_1, d_{1,0}), ..., (q_1, d_{1,n}) ]\n",
    "        ]\n",
    "        Which we then flatten along the batch dimension. It would likely be more efficient\n",
    "        to rewrite the matrix multiplications in the relevance matchers, but this is a more general solution.\n",
    "        \"\"\"\n",
    "\n",
    "        embedded_text = embedded_text.unsqueeze(1).expand(-1, embedded_options.size(1), -1, -1) # [batch, num_options, words, dim]\n",
    "        mask = mask.unsqueeze(1).expand(-1, embedded_options.size(1), -1)\n",
    "        \n",
    "        scores = self._relevance_matcher(embedded_text, embedded_options, mask, options_mask).squeeze(-1)\n",
    "        probs = torch.sigmoid(scores)\n",
    "\n",
    "        output_dict = {\"logits\": scores, \"probs\": probs}\n",
    "        output_dict[\"token_ids\"] = util.get_token_ids_from_text_field_tensors(tokens)\n",
    "        if labels is not None:\n",
    "            label_mask = (labels != -1)\n",
    "            \n",
    "            self._mrr(probs, labels, label_mask)\n",
    "            self._ndcg(probs, labels, label_mask)\n",
    "            \n",
    "            probs = probs.view(-1)\n",
    "            labels = labels.view(-1)\n",
    "            label_mask = label_mask.view(-1)\n",
    "            \n",
    "            self._auc(probs, labels.ge(0.5).long(), label_mask)\n",
    "            \n",
    "            loss = self._loss(probs, labels)\n",
    "            output_dict[\"loss\"] = loss.masked_fill(~label_mask, 0).sum() / label_mask.sum()\n",
    "\n",
    "        return output_dict\n",
    "\n",
    "    @overrides\n",
    "    def make_output_human_readable(\n",
    "        self, output_dict: Dict[str, torch.Tensor]\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        return output_dict\n",
    "\n",
    "    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n",
    "        metrics = {\n",
    "            \"auc\": self._auc.get_metric(reset),\n",
    "            \"mrr\": self._mrr.get_metric(reset),\n",
    "            \"ndcg\": self._ndcg.get_metric(reset),\n",
    "        }\n",
    "        return metrics\n",
    "\n",
    "    default_predictor = \"document_ranker\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#This is where `data_split.py` will save your data by default\n",
    "DATA_ROOT = \"/tmp/allenrank/data/mimics-clickexplore/%s\";\n",
    "MODEL_NAME = \"google/bert_uncased_L-2_H-128_A-2\";\n",
    "\n",
    "config = {\n",
    "  \"dataset_reader\": {\n",
    "    \"type\": \"mimics\",\n",
    "    \"tokenizer\": {\n",
    "      \"type\": \"pretrained_transformer\",\n",
    "      \"model_name\": MODEL_NAME,\n",
    "    },\n",
    "    \"token_indexers\": {\n",
    "      \"tokens\": {\n",
    "        \"type\": \"pretrained_transformer\",\n",
    "        \"model_name\": MODEL_NAME,\n",
    "      }\n",
    "    },\n",
    "    \"max_instances\": 50000 # use a smaller subset for demo purposes\n",
    "  },\n",
    "  \"train_data_path\": DATA_ROOT % \"train.tsv\",\n",
    "  \"validation_data_path\": DATA_ROOT % \"valid.tsv\",\n",
    "\n",
    "  \"model\": {\n",
    "    \"type\": \"ranker\",\n",
    "    \"dropout\": 0.35,\n",
    "    \"text_field_embedder\": {\n",
    "      \"token_embedders\": {\n",
    "        \"tokens\": {\n",
    "          \"type\": \"pretrained_transformer\",\n",
    "          \"model_name\": MODEL_NAME,\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    \"relevance_matcher\": {\n",
    "      \"type\": \"bert_cls\",\n",
    "      \"input_dim\": 128,\n",
    "    }\n",
    "  },\n",
    "  \"data_loader\": {\n",
    "    \"type\": \"default\",\n",
    "    \"batch_size\" : 256\n",
    "  },\n",
    "  \"trainer\": {\n",
    "    \"num_epochs\": 5,\n",
    "    \"validation_metric\": \"+auc\",\n",
    "    \"optimizer\": {\n",
    "      \"type\": \"adam\",\n",
    "      \"lr\": 0.0005\n",
    "    },\n",
    "    \"learning_rate_scheduler\": {\n",
    "        \"type\": \"reduce_on_plateau\",\n",
    "        \"factor\": 0.5,\n",
    "        \"mode\": \"max\",\n",
    "        \"patience\": 0\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error loading _jsonnet (this is expected on Windows), treating E:\\7th sem\\AI\\AI\\FinalProject\\Your First Model/training_config - Copy.json as plain json\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] The process cannot access the file because it is being used by another process: 'E:\\\\7th sem\\\\AI\\\\AI\\\\FinalProject\\\\Your First Model\\\\allennlp_ranking_guide\\\\dist'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-9d4920f45779>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m                           \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                           \u001b[0mfile_friendly_logging\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                           force=True)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\allennlp\\commands\\train.py\u001b[0m in \u001b[0;36mtrain_model_from_file\u001b[1;34m(parameter_filename, serialization_dir, overrides, recover, force, node_rank, include_package, dry_run, file_friendly_logging)\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0minclude_package\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minclude_package\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[0mdry_run\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdry_run\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m         \u001b[0mfile_friendly_logging\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfile_friendly_logging\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m     )\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\allennlp\\commands\\train.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(params, serialization_dir, recover, force, node_rank, include_package, dry_run, file_friendly_logging)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[0mcommon_logging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFILE_FRIENDLY_LOGGING\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_friendly_logging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m     \u001b[0mtraining_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_serialization_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserialization_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecover\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m     \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserialization_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCONFIG_NAME\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\allennlp\\training\\util.py\u001b[0m in \u001b[0;36mcreate_serialization_dir\u001b[1;34m(params, serialization_dir, recover, force)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserialization_dir\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mforce\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m         \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserialization_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserialization_dir\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserialization_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Python\\PythonInstall\\envs\\new\\lib\\shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[1;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[0;32m    514\u001b[0m             \u001b[1;31m# can't continue even if onerror hook returns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_rmtree_unsafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;31m# Allow introspection of whether or not the hardening against symlink\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Python\\PythonInstall\\envs\\new\\lib\\shutil.py\u001b[0m in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    393\u001b[0m                 \u001b[0monerror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mislink\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m             \u001b[0m_rmtree_unsafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    396\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Python\\PythonInstall\\envs\\new\\lib\\shutil.py\u001b[0m in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    393\u001b[0m                 \u001b[0monerror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mislink\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m             \u001b[0m_rmtree_unsafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    396\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Python\\PythonInstall\\envs\\new\\lib\\shutil.py\u001b[0m in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m         \u001b[0monerror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[1;31m# Version using fd-based APIs to protect against races\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Python\\PythonInstall\\envs\\new\\lib\\shutil.py\u001b[0m in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    400\u001b[0m                 \u001b[0monerror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[0monerror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] The process cannot access the file because it is being used by another process: 'E:\\\\7th sem\\\\AI\\\\AI\\\\FinalProject\\\\Your First Model\\\\allennlp_ranking_guide\\\\dist'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "serialization_dir =  os.getcwd()\n",
    "config_filename = serialization_dir + \"/training_config.json\"\n",
    "with open(config_filename, 'w') as config_file:\n",
    "    json.dump(config, config_file)\n",
    "    open(config_filename, 'w').close()\n",
    "    \n",
    "from allennlp.commands.train import train_model_from_file\n",
    "    # Instead of this python code, you would typically just call\n",
    "    # allennlp train [config_file] -s [serialization_dir]\n",
    "open(config_filename).close()\n",
    "\n",
    "train_model_from_file('E:\\\\7th sem\\\\AI\\\\AI\\\\FinalProject\\\\Your First Model/training_config - Copy.json',\n",
    "                          os.getcwd(),\n",
    "                          file_friendly_logging=True,\n",
    "                          force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(config_filename, 'w').close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempfile.TemporaryDirectory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
