{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Preprocessing and Augmentation\n",
    "\n",
    "Image data is, obviously, a bit different from other kinds of numerical data. As a result we apply different preprocessing techniques to it. Like other kinds of data, we still commonly rescale pixel data from the common integer range 0-255 to floats between 0-1. \n",
    "\n",
    "Unique to images, we may choose to flatten RGB data into grayscale, and perform other kinds of image specific transformations that either save processing time or remove noise from the data. Because of the input requirements of neural networks, it is also typically reqeuired that our images all be the same size, so image resizing is almost always applied to our input images, taking care to keep the original aspect ratio can improve performance over squashing images as well. \n",
    "\n",
    "We may also want to perform a number of simple transformations to our dataset: an image upside down is the same image, and our classifier should recognize it as such. \n",
    "\n",
    "First, lets load some sample images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image as keras_image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "photo_location = 'sample_images/'\n",
    "\n",
    "for name in os.listdir(photo_location):\n",
    "    if name.startswith('.'): continue # Avoid looking at hidden files, which the OS sometimes puts in the folder\n",
    "    image = keras_image.load_img(photo_location + name)\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first problem with these images is that they're not only differnt sizes. Keras has some built in functionality to resize the images... but it doesn't actually do the best job in every circumstance. Lets see why:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in os.listdir(photo_location):\n",
    "    if name.startswith('.'): continue \n",
    "    \n",
    "    # Note the target_size parameter\n",
    "    image = keras_image.load_img(photo_location + name, target_size=(256, 256))\n",
    "    print(type(image))\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is enough to let our neural networks process the images, since they're the same size. But the images have been squashed. I hope we all agree the goldfish in particular looks a bit less fish-like then it did before... \n",
    "\n",
    "There has been some discussion of adding this option to Keras, but to my knowledge the feature has never been adopted. \n",
    "\n",
    "That's okay, we can hack together some code that resizes the image with padding using the Python Image Library (PIL). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "\n",
    "# Return an image padded to be square with the specified background size\n",
    "# default is black.\n",
    "def square_image(image, background_color=(0, 0 , 0)):\n",
    "    width, height = image.size\n",
    "    if width == height:\n",
    "        result = image\n",
    "    elif width > height:\n",
    "        result = Image.new(image.mode, (width, width), background_color)\n",
    "        result.paste(image, (0, (width - height) // 2))\n",
    "    else:\n",
    "        result = Image.new(image.mode, (height, height), background_color)\n",
    "        result.paste(image, ((height - width) // 2, 0))\n",
    "\n",
    "    return result\n",
    "\n",
    "# This function takes an image path, loads the image using PIL\n",
    "# and then returns version of that image which is padded to be\n",
    "# square then resized to the specified target. Finally, we'll\n",
    "# just return the image data as a numpy 3D array, which is better\n",
    "# for the rest of our processing goals. \n",
    "\n",
    "# As shown above, keras relies on PIL under the hood already\n",
    "# so this is a good way to go without adding dependencies. \n",
    "def load_maintain_aspect_ratio(input_image_path, target_size):\n",
    "    image = Image.open(input_image_path)\n",
    "    image = square_image(image).resize(target_size)\n",
    "    \n",
    "    # Get the image data as a numpy array.\n",
    "    image = np.array(image.getdata()).reshape(image.size[0], image.size[1], 3)\n",
    "    \n",
    "    # Last thing: we're going to scale all the default (0-255) RGB\n",
    "    # values to be floats from 0-1. If we do not do this in some cases\n",
    "    # the generators we use below wrongly interpret the int's as floats\n",
    "    # and clip values greater than 1. It's a strange bug you wouldn't expect\n",
    "    # so it's better to just handle it here!\n",
    "    return np.divide(image, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in os.listdir(photo_location):\n",
    "    if name.startswith('.'): continue \n",
    "    \n",
    "    # Note the target_size parameter\n",
    "    image = load_maintain_aspect_ratio(photo_location + name, target_size=(256, 256))\n",
    "    print(type(image))\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much better. Now, we'll marvel at how much work Keras does for us with the incredible ImageDataGenerator class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images, we'll use this repeatedly.\n",
    "images = []\n",
    "labels = np.array([0, 1, 2]) # This are required for flow, which we'll see soon.\n",
    "for name in os.listdir(photo_location):\n",
    "    if name.startswith('.'): continue \n",
    "    \n",
    "    # Note the target_size parameter\n",
    "    image = load_maintain_aspect_ratio(photo_location + name, target_size=(256, 256))\n",
    "    images.append(image)\n",
    "    \n",
    "# Just prove to ourselves nothing has changed here:\n",
    "images = np.array(images)\n",
    "for im in images:\n",
    "    plt.imshow(im)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# This class creates a generator that yields images. \n",
    "# The arguments all relate to things we can ask Keras to do\n",
    "# to the images passed into the generator before each image is yielded. \n",
    "# If we use the default values (As we are below) then we'll just get the\n",
    "# same images back. Taken all at once it's a bit overwhelming. Lets just\n",
    "# show how to use this to get the images back out:\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-06,\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0.0,\n",
    "    height_shift_range=0.0,\n",
    "    brightness_range=None,\n",
    "    shear_range=0.0, \n",
    "    zoom_range=0.0, \n",
    "    channel_shift_range=0.0, \n",
    "    fill_mode='nearest', \n",
    "    cval=0.0,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    rescale=None,\n",
    "    preprocessing_function=None,\n",
    "    data_format=None,\n",
    "    validation_split=0.0,\n",
    "    dtype=None)\n",
    "\n",
    "# The above is the same as this:\n",
    "datagen = ImageDataGenerator()\n",
    "\n",
    "# The flow method loops forever by design, as it's meant to be used in combination\n",
    "# with keras fit_generator method. Each time we loop it will yield a batch of images\n",
    "# which, by default, will be ALL of them. With the default parameters, it will yield\n",
    "# our three original images\n",
    "for image_batch, label_batch in datagen.flow(images, labels):\n",
    "    for image, label in zip(image_batch, label_batch):\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "        \n",
    "    break # to avoid infinity..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a quick helper so we don't copy this code over and over...\n",
    "# And make the display a little nicer. \n",
    "def display_images(datagen, rounds=1):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    i = 0\n",
    "    for image_batch, label_batch in datagen.flow(images, labels):\n",
    "        j = 1\n",
    "        for image, label in zip(image_batch, label_batch):\n",
    "            ax = plt.subplot(rounds, 3, (i*3)+j)\n",
    "            ax.axis('off')\n",
    "            plt.imshow(image)\n",
    "            \n",
    "            j += 1\n",
    "\n",
    "        i += 1\n",
    "        if i >= rounds: break # to avoid infinity...\n",
    "        \n",
    "            \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some flips:\n",
    "datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    ")\n",
    "\n",
    "display_images(datagen, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you tell what the data generator did here? \n",
    "\n",
    "We ran through 2 rounds of data generation and the images were randomly shuffled, and the augmentation we asked for (flips) was randomly applied. Lets look at some more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data around, and center it around 0.\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True\n",
    ")\n",
    "\n",
    "# Our requested transformation will not applied without .fit, \n",
    "# because this particular transformation requires information \n",
    "# about the data being passed in.\n",
    "datagen.fit(images)\n",
    "\n",
    "# We can see from the warnings that these transformations do not maintain the 0-1ness of our data\n",
    "# In fact, these two combined normalize the data so that the mean is 0 and the std_deviation is 1\n",
    "# which means we can't really visualize the data perfectly anymore... but you can still get an idea\n",
    "# of how this transform changes the image data by looking at it:\n",
    "display_images(datagen, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random rotations\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=360\n",
    ")\n",
    "\n",
    "# we don't really have to fit for this one, but it's a good idea \n",
    "# to always add this code anyway. It doesn't hurt. \n",
    "datagen.fit(images)\n",
    "display_images(datagen, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift things around, notice here that the edges of some\n",
    "# of these images gets pretty weird... we can tell the \n",
    "# preprocessor to do something different when it has to \n",
    "# fill in pixels that don't exist... see next \n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=100.0,\n",
    "    height_shift_range=100.0,\n",
    ")\n",
    "\n",
    "\n",
    "datagen.fit(images)\n",
    "display_images(datagen, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I prefer this to the default \"nearest\" \n",
    "# esp. since we're already padding images \n",
    "# to squares with black pixels. \n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=100.0,\n",
    "    height_shift_range=100.0,\n",
    "    fill_mode='constant',\n",
    "    cval=0 # black\n",
    ")\n",
    "\n",
    "datagen.fit(images)\n",
    "display_images(datagen, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shear, zoom. Taken to the extreme these aren't that useful...\n",
    "datagen = ImageDataGenerator(\n",
    "    shear_range=360.0, # 0-360, degrees\n",
    "    zoom_range=2.0,    # Scalar, this allows 2x zoom factor\n",
    "    fill_mode='constant',\n",
    "    cval=0 # black\n",
    ")\n",
    "\n",
    "# I hope you agree some of these images might as well be noise, and would \n",
    "# damage our network's ability to learn. \n",
    "datagen.fit(images)\n",
    "display_images(datagen, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shear, zoom. But less extreme, esp. shear\n",
    "# \n",
    "datagen = ImageDataGenerator(\n",
    "    shear_range=10.0, # 0-10, degrees\n",
    "    zoom_range=.5,    # Scalar, this allows increase/decrease size by 50%\n",
    "    fill_mode='constant',\n",
    "    cval=0 # black\n",
    ")\n",
    "\n",
    "\n",
    "datagen.fit(images)\n",
    "display_images(datagen, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken all together, these transformations may increase the time it takes to train\n",
    "# but that's okay... they also have been shown to significantly improve performance\n",
    "# plus, they essentially expand the total size of our dataset, which can allow us\n",
    "# to perform deep learning while collecting less data! \n",
    "\n",
    "# Lets look at one last thing, a good starting point for a genuine generator for use \n",
    "# on a real system:\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=360,\n",
    "    width_shift_range=0.2,   # As a float this is the fraction of the width\n",
    "    height_shift_range=0.2,  # As a float this is the fraction of the height\n",
    "    shear_range=10, \n",
    "    zoom_range=0.5, \n",
    "    fill_mode='constant', \n",
    "    cval=0.0\n",
    ")\n",
    "\n",
    "datagen.fit(images) # This takes awhile now!\n",
    "display_images(datagen, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57340 sentences in the corpus.\n",
      "There are 45872 sentences in the training set.\n",
      "There are 11468 sentences in the testing set.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.core.display import HTML\n",
    "from itertools import chain\n",
    "from collections import Counter, defaultdict, namedtuple, OrderedDict\n",
    "from pomegranate import State, HiddenMarkovModel, DiscreteDistribution\n",
    "import os\n",
    "from io import BytesIO\n",
    "from itertools import chain\n",
    "import random\n",
    "Sentence = namedtuple(\"Sentence\", \"words tags\")\n",
    "\n",
    "def read_data(filename):\n",
    "    \"\"\"Read tagged sentence data\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        sentence_lines = [l.split(\"\\n\") for l in f.read().split(\"\\n\\n\")]\n",
    "    return OrderedDict(((s[0], Sentence(*zip(*[l.strip().split(\"\\t\")\n",
    "                        for l in s[1:]]))) for s in sentence_lines if s[0]))\n",
    "\n",
    "\n",
    "def read_tags(filename):\n",
    "    \"\"\"Read a list of word tag classes\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        tags = f.read().split(\"\\n\")\n",
    "    return frozenset(tags)\n",
    "\n",
    "Sentence = namedtuple(\"Sentence\", \"words tags\")\n",
    "\n",
    "def read_data(filename):\n",
    "    \"\"\"Read tagged sentence data\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        sentence_lines = [l.split(\"\\n\") for l in f.read().split(\"\\n\\n\")]\n",
    "    return OrderedDict(((s[0], Sentence(*zip(*[l.strip().split(\"\\t\")\n",
    "                        for l in s[1:]]))) for s in sentence_lines if s[0]))\n",
    "\n",
    "def read_tags(filename):\n",
    "    \"\"\"Read a list of word tag classes\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        tags = f.read().split(\"\\n\")\n",
    "    return frozenset(tags)\n",
    "\n",
    "class Subset(namedtuple(\"BaseSet\", \"sentences keys vocab X tagset Y N stream\")):\n",
    "    def __new__(cls, sentences, keys):\n",
    "        word_sequences = tuple([sentences[k].words for k in keys])\n",
    "        tag_sequences = tuple([sentences[k].tags for k in keys])\n",
    "        wordset = frozenset(chain(*word_sequences))\n",
    "        tagset = frozenset(chain(*tag_sequences))\n",
    "        N = sum(1 for _ in chain(*(sentences[k].words for k in keys)))\n",
    "        stream = tuple(zip(chain(*word_sequences), chain(*tag_sequences)))\n",
    "        return super().__new__(cls, {k: sentences[k] for k in keys}, keys, wordset, word_sequences,\n",
    "                               tagset, tag_sequences, N, stream.__iter__)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.sentences.items())\n",
    "\n",
    "\n",
    "class Dataset(namedtuple(\"_Dataset\", \"sentences keys vocab X tagset Y training_set testing_set N stream\")):\n",
    "    def __new__(cls, tagfile, datafile, train_test_split=0.8, seed=112890):\n",
    "        tagset = read_tags(tagfile)\n",
    "        sentences = read_data(datafile)\n",
    "        keys = tuple(sentences.keys())\n",
    "        wordset = frozenset(chain(*[s.words for s in sentences.values()]))\n",
    "        word_sequences = tuple([sentences[k].words for k in keys])\n",
    "        tag_sequences = tuple([sentences[k].tags for k in keys])\n",
    "        N = sum(1 for _ in chain(*(s.words for s in sentences.values())))\n",
    "        \n",
    "        # split data into train/test sets\n",
    "        _keys = list(keys)\n",
    "        if seed is not None: random.seed(seed)\n",
    "        random.shuffle(_keys)\n",
    "        split = int(train_test_split * len(_keys))\n",
    "        training_data = Subset(sentences, _keys[:split])\n",
    "        testing_data = Subset(sentences, _keys[split:])\n",
    "        stream = tuple(zip(chain(*word_sequences), chain(*tag_sequences)))\n",
    "        return super().__new__(cls, dict(sentences), keys, wordset, word_sequences, tagset,\n",
    "                               tag_sequences, training_data, testing_data, N, stream.__iter__)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.sentences.items())\n",
    "data = Dataset(\"tags-universal.txt\", \"brown-universal.txt\", train_test_split=0.8)\n",
    "\n",
    "print(\"There are {} sentences in the corpus.\".format(len(data)))\n",
    "print(\"There are {} sentences in the training set.\".format(len(data.training_set)))\n",
    "print(\"There are {} sentences in the testing set.\".format(len(data.testing_set)))\n",
    "\n",
    "assert len(data) == len(data.training_set) + len(data.testing_set), \\\n",
    "       \"The number of sentences in the training set + testing set should sum to the number of sentences in the corpus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pomegranate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'b100-38532'\n",
    "print(\"Sentence: {}\".format(key))\n",
    "print(\"words:\\n\\t{!s}\".format(data.sentences[key].words))\n",
    "print(\"tags:\\n\\t{!s}\".format(data.sentences[key].tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
